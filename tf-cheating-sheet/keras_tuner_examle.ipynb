{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://keras-team.github.io/keras-tuner/ <br/>\n",
    "https://autokeras.com/tutorial/image_classification/ <br/>\n",
    "무조건 코랩에서 하자. CPU 터진다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data(path='mnist.npz')\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, \n",
    "                                                  test_size = 0.3, random_state = 777)\n",
    "\n",
    "num_x_train = x_train.shape[0]\n",
    "num_x_val = x_val.shape[0]\n",
    "num_x_test = x_test.shape[0]\n",
    "\n",
    "x_train = (x_train.reshape(-1, 28, 28, 1)) / 255\n",
    "x_val = (x_val.reshape(-1, 28, 28, 1)) / 255\n",
    "x_test = (x_test.reshape(-1, 28, 28, 1)) / 255\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard CNN\n",
    "일반적인 cnn 구조에서 고려할 수 있는 하이퍼파라미터들\n",
    "* conv2d layer : num of filters\n",
    "* Dense layer : num of hidden units\n",
    "* dropout ratio\n",
    "* GAP or GMP ?\n",
    "* Adam : learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.layers import Input, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "inputs = Input(shape = (28, 28, 1))\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation = 'relu')(inputs)\n",
    "x = Conv2D(32, (3, 3), activation = 'relu')(x)\n",
    "x = MaxPooling2D(strides = 2)(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(30, activation = 'relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(10, activation = 'softmax')(x)\n",
    "\n",
    "model = Model(inputs = inputs, outputs = x)\n",
    "\n",
    "model.compile(optimizer = Adam(learning_rate = 0.001), \n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Keras Tuner model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, GlobalMaxPooling2D, Dense\n",
    "from tensorflow.keras.layers import Input, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def build_model(hp):\n",
    "    inputs = Input(shape = (28, 28, 1))\n",
    "    x = inputs\n",
    "\n",
    "    for i in range(hp.Int('n_layers', 1, 3)):\n",
    "        # 필터 개수 탐색\n",
    "        x = Conv2D(\n",
    "            filters = hp.Int('filters_' + str(i), 4, 64, step = 8, default = 16),\n",
    "            kernel_size = (3, 3), activation = 'relu',\n",
    "            padding = 'same')(x)\n",
    "    x = MaxPooling2D(strides = 2)(x)\n",
    "\n",
    "    # GAP? GMP?\n",
    "    if hp.Choice('global_pooling', ['max', 'avg']) == 'avg':\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "    else:\n",
    "        x = GlobalMaxPooling2D()(x)\n",
    "\n",
    "    # 은닉층 노드 개수 탐색\n",
    "    x = Dense(units = hp.Int('units', \n",
    "                          min_value = 16,\n",
    "                          max_value = 128,\n",
    "                          step = 16),\n",
    "            activation = 'relu')(x)\n",
    "    \n",
    "    # 드롭아웃률 탐색\n",
    "    x = Dropout(hp.Choice('dropout_rate', values = [0.2, 0.3, 0.5]))(x)\n",
    "    x = Dense(10, activation = 'softmax')(x)\n",
    "\n",
    "    model = Model(inputs = inputs, outputs = x)\n",
    "    # 학습률 탐색\n",
    "    model.compile(optimizer = Adam(hp.Choice('learning_rate', \n",
    "                                             values = [1e-3, 1e-4, 1e-5])),\n",
    "                loss = 'categorical_crossentropy',\n",
    "                metrics = ['acc'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define tuner and Search param. space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kerastuner.tuners import RandomSearch # or Hyperband\n",
    "\n",
    "tuner = RandomSearch(build_model,                        # 탐색할 모델\n",
    "                     objective='val_acc',                # 모니터링 지표\n",
    "                     max_trials=5,                       # 실험 진행 수 (파라미터세팅)\n",
    "                     executions_per_trial=3,             # 각 실험당 반복 수\n",
    "                     directory='C:\\\\Users\\\\user\\\\study', # 결과 저장될 디렉터리\n",
    "                     project_name='tuner_ex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 6\n",
      "n_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 3, 'step': 1, 'sampling': None}\n",
      "filters_0 (Int)\n",
      "{'default': 16, 'conditions': [], 'min_value': 4, 'max_value': 64, 'step': 8, 'sampling': None}\n",
      "global_pooling (Choice)\n",
      "{'default': 'max', 'conditions': [], 'values': ['max', 'avg'], 'ordered': False}\n",
      "units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 16, 'max_value': 128, 'step': 16, 'sampling': None}\n",
      "dropout_rate (Choice)\n",
      "{'default': 0.2, 'conditions': [], 'values': [0.2, 0.3, 0.5], 'ordered': True}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.001, 'conditions': [], 'values': [0.001, 0.0001, 1e-05], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "# parameter space\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 30m 54s]\n",
      "val_acc: 0.951370378335317\n",
      "\n",
      "Best val_acc So Far: 0.951370378335317\n",
      "Total elapsed time: 02h 47m 44s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "# search param space\n",
    "tuner.search(x=x_train,y=y_train,\n",
    "             epochs=10,\n",
    "             validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in C:\\Users\\user\\study\\tuner_ex\n",
      "Showing 10 best trials\n",
      "Objective(name='val_acc', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_layers: 3\n",
      "filters_0: 20\n",
      "global_pooling: max\n",
      "units: 48\n",
      "dropout_rate: 0.5\n",
      "learning_rate: 0.001\n",
      "filters_1: 12\n",
      "filters_2: 20\n",
      "Score: 0.951370378335317\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_layers: 3\n",
      "filters_0: 20\n",
      "global_pooling: max\n",
      "units: 128\n",
      "dropout_rate: 0.3\n",
      "learning_rate: 0.001\n",
      "filters_1: 12\n",
      "filters_2: 12\n",
      "Score: 0.939981480439504\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_layers: 2\n",
      "filters_0: 44\n",
      "global_pooling: max\n",
      "units: 96\n",
      "dropout_rate: 0.3\n",
      "learning_rate: 1e-05\n",
      "filters_1: 16\n",
      "Score: 0.46174074212710065\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_layers: 2\n",
      "filters_0: 20\n",
      "global_pooling: avg\n",
      "units: 112\n",
      "dropout_rate: 0.5\n",
      "learning_rate: 0.0001\n",
      "filters_1: 12\n",
      "filters_2: 20\n",
      "Score: 0.3933148185412089\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_layers: 3\n",
      "filters_0: 52\n",
      "global_pooling: avg\n",
      "units: 32\n",
      "dropout_rate: 0.2\n",
      "learning_rate: 1e-05\n",
      "filters_1: 20\n",
      "filters_2: 16\n",
      "Score: 0.25696295996507007\n"
     ]
    }
   ],
   "source": [
    "# 실험 결과 요약\n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 28, 28, 20)        200       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 12)        2172      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 20)        2180      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 20)        0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d (Global (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 48)                1008      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                490       \n",
      "=================================================================\n",
      "Total params: 6,050\n",
      "Trainable params: 6,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 성능이 가장 좋았던 모델 호출\n",
    "best_model = tuner.get_best_models()[0]\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_layers': 3,\n",
       " 'filters_0': 20,\n",
       " 'global_pooling': 'max',\n",
       " 'units': 48,\n",
       " 'dropout_rate': 0.5,\n",
       " 'learning_rate': 0.001,\n",
       " 'filters_1': 12,\n",
       " 'filters_2': 20}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best 모델의 하이퍼파라미터 확인\n",
    "best_hp = tuner.get_best_hyperparameters()[0].values\n",
    "best_hp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### keras tuner 사용절차\n",
    ">1. hp를 parameter로 받는 model build함수 정의\n",
    "2. (1)의 함수 정의 과정에서 하이퍼파라미터 튜닝이 필요한 부분에 hp.Int(), hp.Choice()등 초모수 성격에 따라 적절히 범위/범주를 설정하여 api에 맞게 옵션을 걸어준다.\n",
    "3. 사용할 searching 알고리즘(RS, Bayes, HB 등)을 정하여, 실험 및 반복수 등을 설정\n",
    "4. 정의한 searching 알고리즘을 task dataset에 적용시킨다.\n",
    "5. 결과를 확인한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HyperResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kerastuner.tuners import Hyperband\n",
    "from kerastuner.applications import HyperResNet\n",
    "\n",
    "hypermodel = HyperResNet(input_shape=(28, 28, 1), classes=10)\n",
    "\n",
    "tuner = Hyperband(hypermodel,\n",
    "                  objective = 'val_accuracy',\n",
    "                  max_epochs = 10,\n",
    "                  directory='C:\\\\Users\\\\user\\\\study',\n",
    "                  project_name='tuner_resnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(x_train, y_train, epochs = 10, validation_data = (x_val, y_val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
