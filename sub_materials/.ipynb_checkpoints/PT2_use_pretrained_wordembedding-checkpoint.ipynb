{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "HdfmMkfA7MsT"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aiY9vCr58aLR"
   },
   "source": [
    "# Experiments on Newsgroup20 dataset\n",
    "---\n",
    "> Word Embedding\n",
    "* Glove\n",
    "* Word2Vec\n",
    "* training from scratch\n",
    "\n",
    "> Model\n",
    "* Uni-LSTM\n",
    "* Uni-GRU\n",
    "* Bi-LSTM\n",
    "* Bi-GRU\n",
    "* 1D convnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qQvHVH5k9Irk"
   },
   "source": [
    "## 1. Data Exploring & Preparing\n",
    "* data_dir에는 20개의 뉴스 그룹 하위 폴더가 있음\n",
    "* 각각의 하위폴더에는 1000개씩의 text파일이 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"C:/Users/user/study/HandsOnDL/sub_materials/dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "su41UaTW8OWd",
    "outputId": "4d0b09ad-e178-48ce-e8c8-aac24654da40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/news20.tar.gz\n",
      "17334272/17329808 [==============================] - 141s 8us/step\n",
      "Number of directories: 20\n",
      "Directory names: ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
      "Number of files in comp.graphics: 1000\n",
      "Some example filenames: ['37261', '37913', '37914', '37915', '37916']\n"
     ]
    }
   ],
   "source": [
    "data_path = keras.utils.get_file(\n",
    "    \"news20.tar.gz\",\n",
    "    \"http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/news20.tar.gz\",\n",
    "    untar=True,\n",
    ")\n",
    "\n",
    "import pathlib\n",
    "\n",
    "data_dir = pathlib.Path(data_path).parent / \"20_newsgroup\"\n",
    "dirnames = os.listdir(data_dir)\n",
    "print(\"Number of directories:\", len(dirnames))\n",
    "print(\"Directory names:\", dirnames)\n",
    "\n",
    "fnames = os.listdir(data_dir / \"comp.graphics\")\n",
    "print(\"Number of files in comp.graphics:\", len(fnames))\n",
    "print(\"Some example filenames:\", fnames[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CnO7xFjK9re0",
    "outputId": "b07c3905-7e2d-4a46-c160-23f7e7495d6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newsgroups: comp.graphics\n",
      "Path: cantaloupe.srv.cs.cmu.edu!das-news.harvard.edu!noc.near.net!howland.reston.ans.net!agate!dog.ee.lbl.gov!network.ucsd.edu!usc!rpi!nason110.its.rpi.edu!mabusj\n",
      "From: mabusj@nason110.its.rpi.edu (Jasen M. Mabus)\n",
      "Subject: Looking for Brain in CAD\n",
      "Message-ID: <c285m+p@rpi.edu>\n",
      "Nntp-Posting-Host: nason110.its.rpi.edu\n",
      "Reply-To: mabusj@rpi.edu\n",
      "Organization: Rensselaer Polytechnic Institute, Troy, NY.\n",
      "Date: Thu, 29 Apr 1993 23:27:20 GMT\n",
      "Lines: 7\n",
      "\n",
      "Jasen Mabus\n",
      "RPI student\n",
      "\n",
      "\tI am looking for a hman brain in any CAD (.dxf,.cad,.iges,.cgm,etc.) or picture (.gif,.jpg,.ras,etc.) format for an animation demonstration. If any has or knows of a location please reply by e-mail to mabusj@rpi.edu.\n",
      "\n",
      "Thank you in advance,\n",
      "Jasen Mabus  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(open(data_dir / \"comp.graphics\" / \"38987\").read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aGlsDgwzC_Q3"
   },
   "source": [
    ">article 본문 외에 부가적인 정보들을 포함하는 header 부분이 있음.<br/>전처리를 통해 날려줄 것."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NFfc-GDpBK89",
    "outputId": "7bdd62fc-76d1-4a9c-af2d-49b2aa090576"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing alt.atheism, 1000 files found\n",
      "Processing comp.graphics, 1000 files found\n",
      "Processing comp.os.ms-windows.misc, 1000 files found\n",
      "Processing comp.sys.ibm.pc.hardware, 1000 files found\n",
      "Processing comp.sys.mac.hardware, 1000 files found\n",
      "Processing comp.windows.x, 1000 files found\n",
      "Processing misc.forsale, 1000 files found\n",
      "Processing rec.autos, 1000 files found\n",
      "Processing rec.motorcycles, 1000 files found\n",
      "Processing rec.sport.baseball, 1000 files found\n",
      "Processing rec.sport.hockey, 1000 files found\n",
      "Processing sci.crypt, 1000 files found\n",
      "Processing sci.electronics, 1000 files found\n",
      "Processing sci.med, 1000 files found\n",
      "Processing sci.space, 1000 files found\n",
      "Processing soc.religion.christian, 997 files found\n",
      "Processing talk.politics.guns, 1000 files found\n",
      "Processing talk.politics.mideast, 1000 files found\n",
      "Processing talk.politics.misc, 1000 files found\n",
      "Processing talk.religion.misc, 1000 files found\n",
      "Classes: ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
      "Number of samples: 19997\n"
     ]
    }
   ],
   "source": [
    "samples = []\n",
    "labels = []\n",
    "class_names = []\n",
    "class_index = 0\n",
    "for dirname in sorted(os.listdir(data_dir)):   # subject별 디렉토리 순회\n",
    "    class_names.append(dirname)\n",
    "    dirpath = data_dir / dirname\n",
    "    fnames = os.listdir(dirpath)\n",
    "    print(\"Processing %s, %d files found\" % (dirname, len(fnames)))\n",
    "    for fname in fnames:                       # 개별 subject 내부 파일 순회\n",
    "        fpath = dirpath / fname\n",
    "        f = open(fpath, encoding=\"latin-1\")\n",
    "        content = f.read()\n",
    "        lines = content.split(\"\\n\")            # 줄별로 분리\n",
    "        lines = lines[10:]                     # header 날리기\n",
    "        content = \"\\n\".join(lines)             # 다시 분리된 line들을 다시 합치기\n",
    "        samples.append(content)                # 전처리한 text를 sample목록에 추가\n",
    "        labels.append(class_index)\n",
    "    class_index += 1\n",
    "\n",
    "print(\"Classes:\", class_names)\n",
    "print(\"Number of samples:\", len(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "a4LvCMt6Ekk1"
   },
   "outputs": [],
   "source": [
    "# # data shuffle\n",
    "# seed = 2021\n",
    "# rng = np.random.RandomState(seed)\n",
    "# rng.shuffle(samples)\n",
    "# rng = np.random.RandomState(seed)\n",
    "# rng.shuffle(labels)\n",
    "\n",
    "# # train / valid split\n",
    "# validation_split = 0.2\n",
    "# num_validation_samples = int(validation_split * len(samples))\n",
    "# train_samples = samples[:-num_validation_samples]\n",
    "# val_samples = samples[-num_validation_samples:]\n",
    "# train_labels = labels[:-num_validation_samples]\n",
    "# val_labels = labels[-num_validation_samples:]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_samples, train_labels, val_samples, val_labels =\\\n",
    "    train_test_split(samples, labels, test_size = 0.2, random_state = 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o0w3r8QlHaNu"
   },
   "source": [
    "## 2. Create a Vocabulary Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LoNSiXsyIOoW"
   },
   "source": [
    "* TextVectorization : batch의 각 sample string을 token indices의 list로 변환한다. <br/>\n",
    "\n",
    "구체적인 과정은 다음과 같다.\n",
    "\n",
    "1. standardize each sample (usually lowercasing + punctuation stripping)\n",
    "2. split each sample into substrings (usually words)\n",
    "3. recombine substrings into tokens (usually ngrams)\n",
    "4. index tokens (associate a unique int value with each token)\n",
    "5. transform each sample using this index, either into a vector of ints or a dense float vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "hIR7KAyYHYSk"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "# 빈도순으로 20000개의 단어만 고려할 것이며, output되는 시퀀스의 길이는 200으로 할 것임\n",
    "vectorizer = TextVectorization(max_tokens=20000, \n",
    "                               output_sequence_length=200)\n",
    "text_ds = tf.data.Dataset.from_tensor_slices(train_samples).batch(128)\n",
    "vectorizer.adapt(text_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vTAf2IQiJtzH",
    "outputId": "b7ae12b4-a646-4f86-ad36-dd8f5f160196"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'the', b'to', b'of', b'a', b'and', b'in', b'is', b'i', b'that', b'it']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top 10 words\n",
    "vectorizer.get_vocabulary()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VWaGrf6LJ0KA",
    "outputId": "6c84fabd-5919-4d7c-ece8-99451c653761"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   2, 3830, 1678,   15,    2, 6367,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0],\n",
       "       [   9,  118,    3,  825,   69, 2193, 2561,   34,  224,  220,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectorization example\n",
    "output = vectorizer([[\"the cat sat on the mat\"], \n",
    "                     [\"i want to study only deep learning all day long.\"]])\n",
    "output.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "qXUR6b_PKiUA"
   },
   "outputs": [],
   "source": [
    "# get dictionary mapping words to indices\n",
    "voc = vectorizer.get_vocabulary()\n",
    "word_index = dict(zip(voc, range(len(voc))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'the',\n",
       " b'to',\n",
       " b'of',\n",
       " b'a',\n",
       " b'and',\n",
       " b'in',\n",
       " b'is',\n",
       " b'i',\n",
       " b'that',\n",
       " b'it',\n",
       " b'for',\n",
       " b'you',\n",
       " b'this',\n",
       " b'on',\n",
       " b'be',\n",
       " b'not',\n",
       " b'are',\n",
       " b'have',\n",
       " b'with',\n",
       " b'as',\n",
       " b'or',\n",
       " b'if',\n",
       " b'was',\n",
       " b'but',\n",
       " b'they',\n",
       " b'from',\n",
       " b'by',\n",
       " b'at',\n",
       " b'an',\n",
       " b'my',\n",
       " b'can',\n",
       " b'what',\n",
       " b'all',\n",
       " b'would',\n",
       " b'there',\n",
       " b'one',\n",
       " b'will',\n",
       " b'do',\n",
       " b'about',\n",
       " b'writes',\n",
       " b'we',\n",
       " b'so',\n",
       " b'he',\n",
       " b'has',\n",
       " b'your',\n",
       " b'no',\n",
       " b'article',\n",
       " b'any',\n",
       " b'me',\n",
       " b'some',\n",
       " b'who',\n",
       " b'were',\n",
       " b'which',\n",
       " b'its',\n",
       " b'out',\n",
       " b'dont',\n",
       " b'when',\n",
       " b'people',\n",
       " b'like',\n",
       " b'just',\n",
       " b'more',\n",
       " b'their',\n",
       " b'know',\n",
       " b'1',\n",
       " b'other',\n",
       " b'them',\n",
       " b'up',\n",
       " b'only',\n",
       " b'get',\n",
       " b'had',\n",
       " b'how',\n",
       " b'than',\n",
       " b'been',\n",
       " b'think',\n",
       " b'his',\n",
       " b'lines',\n",
       " b'also',\n",
       " b'2',\n",
       " b'x',\n",
       " b'then',\n",
       " b'does',\n",
       " b'use',\n",
       " b'time',\n",
       " b'im',\n",
       " b'these',\n",
       " b'should',\n",
       " b'could',\n",
       " b'well',\n",
       " b'new',\n",
       " b'us',\n",
       " b'good',\n",
       " b'may',\n",
       " b'because',\n",
       " b'even',\n",
       " b'now',\n",
       " b'am',\n",
       " b'very',\n",
       " b'see',\n",
       " b'into',\n",
       " b'those',\n",
       " b'why',\n",
       " b'0',\n",
       " b'way',\n",
       " b'much',\n",
       " b'make',\n",
       " b'many',\n",
       " b'first',\n",
       " b'two',\n",
       " b'say',\n",
       " b'most',\n",
       " b'our',\n",
       " b'such',\n",
       " b'right',\n",
       " b'3',\n",
       " b'did',\n",
       " b'god',\n",
       " b'want',\n",
       " b'said',\n",
       " b'where',\n",
       " b'system',\n",
       " b'here',\n",
       " b'being',\n",
       " b'anyone',\n",
       " b'same',\n",
       " b'used',\n",
       " b'after',\n",
       " b'over',\n",
       " b'go',\n",
       " b'work',\n",
       " b'1993',\n",
       " b'something',\n",
       " b'need',\n",
       " b'really',\n",
       " b'4',\n",
       " b'too',\n",
       " b'him',\n",
       " b'since',\n",
       " b'believe',\n",
       " b'problem',\n",
       " b'please',\n",
       " b'still',\n",
       " b'back',\n",
       " b'going',\n",
       " b'ive',\n",
       " b'nntppostinghost',\n",
       " b'before',\n",
       " b'email',\n",
       " b'find',\n",
       " b'might',\n",
       " b'information',\n",
       " b'off',\n",
       " b'take',\n",
       " b'point',\n",
       " b'better',\n",
       " b'things',\n",
       " b'5',\n",
       " b'government',\n",
       " b'both',\n",
       " b'years',\n",
       " b'using',\n",
       " b'cant',\n",
       " b'date',\n",
       " b'file',\n",
       " b'last',\n",
       " b'own',\n",
       " b'never',\n",
       " b'while',\n",
       " b'apr',\n",
       " b'thanks',\n",
       " b'must',\n",
       " b'without',\n",
       " b'university',\n",
       " b'made',\n",
       " b'sure',\n",
       " b'question',\n",
       " b'through',\n",
       " b'doesnt',\n",
       " b'gmt',\n",
       " b'another',\n",
       " b'number',\n",
       " b'read',\n",
       " b'year',\n",
       " b'help',\n",
       " b'thats',\n",
       " b'someone',\n",
       " b'between',\n",
       " b'thing',\n",
       " b'world',\n",
       " b'etc',\n",
       " b'got',\n",
       " b'maxaxaxaxaxaxaxaxaxaxaxaxaxaxax',\n",
       " b'down',\n",
       " b'fact',\n",
       " b'look',\n",
       " b'come',\n",
       " b'part',\n",
       " b'under',\n",
       " b'drive',\n",
       " b'windows',\n",
       " b'available',\n",
       " b'anything',\n",
       " b'didnt',\n",
       " b'few',\n",
       " b'6',\n",
       " b'data',\n",
       " b'each',\n",
       " b'against',\n",
       " b'around',\n",
       " b'program',\n",
       " b'little',\n",
       " b'however',\n",
       " b'10',\n",
       " b'different',\n",
       " b'every',\n",
       " b'again',\n",
       " b'case',\n",
       " b'seems',\n",
       " b'give',\n",
       " b'long',\n",
       " b'power',\n",
       " b'true',\n",
       " b'probably',\n",
       " b'day',\n",
       " b'id',\n",
       " b'least',\n",
       " b'best',\n",
       " b'software',\n",
       " b'enough',\n",
       " b'actually',\n",
       " b'try',\n",
       " b'computer',\n",
       " b'tell',\n",
       " b'state',\n",
       " b'set',\n",
       " b'put',\n",
       " b'law',\n",
       " b'c',\n",
       " b'lot',\n",
       " b'course',\n",
       " b'she',\n",
       " b'though',\n",
       " b'space',\n",
       " b'20',\n",
       " b'great',\n",
       " b'game',\n",
       " b'nothing',\n",
       " b'says',\n",
       " b'support',\n",
       " b'8',\n",
       " b'either',\n",
       " b'car',\n",
       " b'youre',\n",
       " b'far',\n",
       " b'group',\n",
       " b'real',\n",
       " b'run',\n",
       " b'her',\n",
       " b'version',\n",
       " b'mean',\n",
       " b'possible',\n",
       " b'david',\n",
       " b'rather',\n",
       " b'life',\n",
       " b'7',\n",
       " b'name',\n",
       " b'second',\n",
       " b'list',\n",
       " b'others',\n",
       " b'free',\n",
       " b'call',\n",
       " b'wrong',\n",
       " b'reason',\n",
       " b'called',\n",
       " b'else',\n",
       " b'25',\n",
       " b'yes',\n",
       " b'let',\n",
       " b'hard',\n",
       " b'above',\n",
       " b'done',\n",
       " b'john',\n",
       " b'keep',\n",
       " b'old',\n",
       " b'place',\n",
       " b'having',\n",
       " b'found',\n",
       " b'isnt',\n",
       " b'seen',\n",
       " b'line',\n",
       " b'post',\n",
       " b'jesus',\n",
       " b'maybe',\n",
       " b'order',\n",
       " b'ever',\n",
       " b'public',\n",
       " b'able',\n",
       " b'end',\n",
       " b'send',\n",
       " b'example',\n",
       " b'man',\n",
       " b'next',\n",
       " b'key',\n",
       " b'person',\n",
       " b'15',\n",
       " b'bit',\n",
       " b'bad',\n",
       " b'always',\n",
       " b'wrote',\n",
       " b'yet',\n",
       " b'thought',\n",
       " b'following',\n",
       " b'card',\n",
       " b'quite',\n",
       " b'general',\n",
       " b'files',\n",
       " b'problems',\n",
       " b'three',\n",
       " b'references',\n",
       " b'high',\n",
       " b'16',\n",
       " b'heard',\n",
       " b'trying',\n",
       " b'science',\n",
       " b'whether',\n",
       " b'team',\n",
       " b'means',\n",
       " b'looking',\n",
       " b'doing',\n",
       " b'internet',\n",
       " b'image',\n",
       " b'evidence',\n",
       " b'book',\n",
       " b'given',\n",
       " b'12',\n",
       " b'times',\n",
       " b'systems',\n",
       " b'once',\n",
       " b'several',\n",
       " b'start',\n",
       " b'away',\n",
       " b'children',\n",
       " b'less',\n",
       " b'idea',\n",
       " b'ill',\n",
       " b'left',\n",
       " b'control',\n",
       " b'bill',\n",
       " b'q',\n",
       " b'organization',\n",
       " b'during',\n",
       " b'human',\n",
       " b'note',\n",
       " b'phone',\n",
       " b'subject',\n",
       " b'mail',\n",
       " b'kind',\n",
       " b'remember',\n",
       " b'opinions',\n",
       " b'getting',\n",
       " b'seem',\n",
       " b'word',\n",
       " b'saying',\n",
       " b'change',\n",
       " b'message',\n",
       " b'big',\n",
       " b'makes',\n",
       " b'11',\n",
       " b'perhaps',\n",
       " b'o',\n",
       " b'mr',\n",
       " b'home',\n",
       " b'until',\n",
       " b'based',\n",
       " b'cannot',\n",
       " b'already',\n",
       " b'30',\n",
       " b'gun',\n",
       " b'rights',\n",
       " b'today',\n",
       " b'standard',\n",
       " b'ask',\n",
       " b'told',\n",
       " b'chip',\n",
       " b'research',\n",
       " b'came',\n",
       " b'answer',\n",
       " b'president',\n",
       " b'window',\n",
       " b'money',\n",
       " b'jews',\n",
       " b'ago',\n",
       " b'source',\n",
       " b'questions',\n",
       " b'price',\n",
       " b'local',\n",
       " b'disk',\n",
       " b'bible',\n",
       " b'theres',\n",
       " b'agree',\n",
       " b'christian',\n",
       " b'small',\n",
       " b'whole',\n",
       " b'states',\n",
       " b'stuff',\n",
       " b'large',\n",
       " b'matter',\n",
       " b'israel',\n",
       " b'days',\n",
       " b'national',\n",
       " b'21',\n",
       " b'm',\n",
       " b'issue',\n",
       " b'p',\n",
       " b'pretty',\n",
       " b'interested',\n",
       " b'fire',\n",
       " b'american',\n",
       " b'address',\n",
       " b'running',\n",
       " b'mark',\n",
       " b'b',\n",
       " b'games',\n",
       " b'feel',\n",
       " b'everything',\n",
       " b'works',\n",
       " b'hope',\n",
       " b'love',\n",
       " b'war',\n",
       " b'fax',\n",
       " b'religion',\n",
       " b'simply',\n",
       " b'code',\n",
       " b'went',\n",
       " b'started',\n",
       " b'graphics',\n",
       " b'9',\n",
       " b'show',\n",
       " b'including',\n",
       " b'news',\n",
       " b'current',\n",
       " b'buy',\n",
       " b'often',\n",
       " b'understand',\n",
       " b'original',\n",
       " b'live',\n",
       " b'history',\n",
       " b'claim',\n",
       " b'box',\n",
       " b'turkish',\n",
       " b'care',\n",
       " b'14',\n",
       " b'truth',\n",
       " b'mac',\n",
       " b'center',\n",
       " b'full',\n",
       " b'd',\n",
       " b'wouldnt',\n",
       " b'fbi',\n",
       " b'play',\n",
       " b'church',\n",
       " b'wont',\n",
       " b'important',\n",
       " b'everyone',\n",
       " b'info',\n",
       " b'certainly',\n",
       " b'machine',\n",
       " b'guess',\n",
       " b'almost',\n",
       " b'later',\n",
       " b'armenian',\n",
       " b'cause',\n",
       " b'open',\n",
       " b'technology',\n",
       " b'instead',\n",
       " b'side',\n",
       " b'making',\n",
       " b'working',\n",
       " b'ones',\n",
       " b'themselves',\n",
       " b'mind',\n",
       " b'dos',\n",
       " b'comes',\n",
       " b'24',\n",
       " b'access',\n",
       " b'area',\n",
       " b'although',\n",
       " b'e',\n",
       " b'93',\n",
       " b'april',\n",
       " b'pay',\n",
       " b'value',\n",
       " b'memory',\n",
       " b'include',\n",
       " b'hell',\n",
       " b'ftp',\n",
       " b'type',\n",
       " b's',\n",
       " b'speed',\n",
       " b'hand',\n",
       " b'sun',\n",
       " b'ie',\n",
       " b'words',\n",
       " b'50',\n",
       " b'programs',\n",
       " b'anyway',\n",
       " b'house',\n",
       " b'write',\n",
       " b'within',\n",
       " b'usa',\n",
       " b'sense',\n",
       " b'13',\n",
       " b'country',\n",
       " b'consider',\n",
       " b'michael',\n",
       " b'22',\n",
       " b'100',\n",
       " b'difference',\n",
       " b'pc',\n",
       " b'earth',\n",
       " b'sort',\n",
       " b'men',\n",
       " b'unless',\n",
       " b'18',\n",
       " b'single',\n",
       " b'talking',\n",
       " b'j',\n",
       " b'hes',\n",
       " b'w',\n",
       " b'tried',\n",
       " b'light',\n",
       " b'likely',\n",
       " b'paul',\n",
       " b'especially',\n",
       " b'police',\n",
       " b'mike',\n",
       " b'death',\n",
       " b'similar',\n",
       " b'lets',\n",
       " b'private',\n",
       " b'saw',\n",
       " b'net',\n",
       " b'31',\n",
       " b'christ',\n",
       " b'armenians',\n",
       " b'contact',\n",
       " b'black',\n",
       " b'nice',\n",
       " b'christians',\n",
       " b'objective',\n",
       " b'steve',\n",
       " b'opinion',\n",
       " b'r',\n",
       " b'cost',\n",
       " b'exactly',\n",
       " b'couple',\n",
       " b'clear',\n",
       " b'17',\n",
       " b'deal',\n",
       " b'argument',\n",
       " b'encryption',\n",
       " b'jewish',\n",
       " b'known',\n",
       " b'took',\n",
       " b'killed',\n",
       " b'copy',\n",
       " b'faith',\n",
       " b'check',\n",
       " b'religious',\n",
       " b'package',\n",
       " b'certain',\n",
       " b'anybody',\n",
       " b'among',\n",
       " b'white',\n",
       " b'color',\n",
       " b'body',\n",
       " b'situation',\n",
       " b'server',\n",
       " b'ms',\n",
       " b'taken',\n",
       " b'service',\n",
       " b'posting',\n",
       " b'dead',\n",
       " b'display',\n",
       " b'thus',\n",
       " b'company',\n",
       " b'common',\n",
       " b'ok',\n",
       " b'correct',\n",
       " b'asked',\n",
       " b'user',\n",
       " b'win',\n",
       " b'provide',\n",
       " b'night',\n",
       " b'video',\n",
       " b'major',\n",
       " b'myself',\n",
       " b'23',\n",
       " b'scsi',\n",
       " b'simple',\n",
       " b'moral',\n",
       " b'inc',\n",
       " b'view',\n",
       " b'theyre',\n",
       " b'l',\n",
       " b'19',\n",
       " b'usually',\n",
       " b'fine',\n",
       " b'discussion',\n",
       " b'third',\n",
       " b'form',\n",
       " b'except',\n",
       " b'groups',\n",
       " b'theory',\n",
       " b'statement',\n",
       " b'security',\n",
       " b'goes',\n",
       " b'stop',\n",
       " b'via',\n",
       " b'upon',\n",
       " b'havent',\n",
       " b'n',\n",
       " b'become',\n",
       " b'itself',\n",
       " b'health',\n",
       " b'political',\n",
       " b'oh',\n",
       " b'distribution',\n",
       " b'network',\n",
       " b'sorry',\n",
       " b'personal',\n",
       " b'jim',\n",
       " b'gods',\n",
       " b'wanted',\n",
       " b'force',\n",
       " b'rest',\n",
       " b'interesting',\n",
       " b'happened',\n",
       " b'ca',\n",
       " b'books',\n",
       " b'past',\n",
       " b'board',\n",
       " b'players',\n",
       " b'press',\n",
       " b'experience',\n",
       " b'city',\n",
       " b'reading',\n",
       " b'per',\n",
       " b'particular',\n",
       " b'hear',\n",
       " b'therefore',\n",
       " b'advance',\n",
       " b'position',\n",
       " b'written',\n",
       " b'size',\n",
       " b'four',\n",
       " b'whatever',\n",
       " b'business',\n",
       " b'early',\n",
       " b'according',\n",
       " b'society',\n",
       " b'nor',\n",
       " b'mine',\n",
       " b'period',\n",
       " b'future',\n",
       " b'laws',\n",
       " b'turn',\n",
       " b'application',\n",
       " b'sound',\n",
       " b'low',\n",
       " b'happen',\n",
       " b'guns',\n",
       " b'talk',\n",
       " b'head',\n",
       " b'months',\n",
       " b'special',\n",
       " b'department',\n",
       " b'monitor',\n",
       " b'text',\n",
       " b'members',\n",
       " b'due',\n",
       " b'users',\n",
       " b'peace',\n",
       " b'images',\n",
       " b'easy',\n",
       " b'effect',\n",
       " b'add',\n",
       " b'women',\n",
       " b'numbers',\n",
       " b'top',\n",
       " b'needs',\n",
       " b'hardware',\n",
       " b'guy',\n",
       " b'front',\n",
       " b'wasnt',\n",
       " b'united',\n",
       " b'shall',\n",
       " b'fast',\n",
       " b'school',\n",
       " b'israeli',\n",
       " b'recently',\n",
       " b'frank',\n",
       " b'40',\n",
       " b'exist',\n",
       " b'sell',\n",
       " b'uses',\n",
       " b'test',\n",
       " b'model',\n",
       " b'format',\n",
       " b'kill',\n",
       " b'sometimes',\n",
       " b'gets',\n",
       " b'lost',\n",
       " b'accept',\n",
       " b'job',\n",
       " b'driver',\n",
       " b'koresh',\n",
       " b'drivers',\n",
       " b'considered',\n",
       " b'coming',\n",
       " b'canada',\n",
       " b'bike',\n",
       " b'taking',\n",
       " b'whats',\n",
       " b'vs',\n",
       " b'series',\n",
       " b'season',\n",
       " b'expect',\n",
       " b'error',\n",
       " b'level',\n",
       " b'outside',\n",
       " b'hockey',\n",
       " b'hit',\n",
       " b'posted',\n",
       " b'db',\n",
       " b'move',\n",
       " b'hi',\n",
       " b'various',\n",
       " b'james',\n",
       " b'face',\n",
       " b'arent',\n",
       " b'week',\n",
       " b'ground',\n",
       " b'robert',\n",
       " b'process',\n",
       " b'further',\n",
       " b'speak',\n",
       " b'longer',\n",
       " b'worth',\n",
       " b'radio',\n",
       " b'return',\n",
       " b'response',\n",
       " b'higher',\n",
       " b'runs',\n",
       " b'mode',\n",
       " b'result',\n",
       " b'weapons',\n",
       " b'million',\n",
       " b'points',\n",
       " b'necessary',\n",
       " b'federal',\n",
       " b'offer',\n",
       " b'couldnt',\n",
       " b'short',\n",
       " b'san',\n",
       " b'allow',\n",
       " b'assume',\n",
       " b'g',\n",
       " b'dave',\n",
       " b'thinking',\n",
       " b'explain',\n",
       " b'doubt',\n",
       " b'behind',\n",
       " b'action',\n",
       " b'rate',\n",
       " b'present',\n",
       " b'clinton',\n",
       " b'ibm',\n",
       " b'york',\n",
       " b'red',\n",
       " b'together',\n",
       " b'reference',\n",
       " b'drives',\n",
       " b'office',\n",
       " b'land',\n",
       " b'keys',\n",
       " b'includes',\n",
       " b'specific',\n",
       " b'screen',\n",
       " b'knows',\n",
       " b'values',\n",
       " b'strong',\n",
       " b'bob',\n",
       " b'clipper',\n",
       " b'crime',\n",
       " b'gas',\n",
       " b'26',\n",
       " b'32',\n",
       " b'yourself',\n",
       " b'results',\n",
       " b'dod',\n",
       " b'cars',\n",
       " b'report',\n",
       " b'involved',\n",
       " b'medical',\n",
       " b'cases',\n",
       " b'military',\n",
       " b'apple',\n",
       " b'looks',\n",
       " b'story',\n",
       " b'close',\n",
       " b'claims',\n",
       " b'bus',\n",
       " b'leave',\n",
       " b'faq',\n",
       " b'building',\n",
       " b'knowledge',\n",
       " b'young',\n",
       " b'himself',\n",
       " b'previous',\n",
       " b'insurance',\n",
       " b'35',\n",
       " b'unix',\n",
       " b'along',\n",
       " b'study',\n",
       " b'water',\n",
       " b'wants',\n",
       " b'league',\n",
       " b'willing',\n",
       " b'hold',\n",
       " b'total',\n",
       " b'applications',\n",
       " b'soon',\n",
       " b'h',\n",
       " b'deleted',\n",
       " b'asking',\n",
       " b'plus',\n",
       " b'act',\n",
       " b'road',\n",
       " b'lord',\n",
       " b'sin',\n",
       " b'friend',\n",
       " b'27',\n",
       " b'appreciated',\n",
       " b'quality',\n",
       " b'international',\n",
       " b'near',\n",
       " b'sent',\n",
       " b'save',\n",
       " b'armenia',\n",
       " b'peter',\n",
       " b'party',\n",
       " b'parts',\n",
       " b'performance',\n",
       " b'institute',\n",
       " b'28',\n",
       " b'policy',\n",
       " b'anonymous',\n",
       " b'build',\n",
       " b'takes',\n",
       " b'needed',\n",
       " b'weeks',\n",
       " b'washington',\n",
       " b'st',\n",
       " b'ideas',\n",
       " b'none',\n",
       " b'comments',\n",
       " b'ways',\n",
       " b'voice',\n",
       " b'mentioned',\n",
       " b'nature',\n",
       " b'legal',\n",
       " b'created',\n",
       " b'section',\n",
       " b'included',\n",
       " b'complete',\n",
       " b'appears',\n",
       " b'1992',\n",
       " b'output',\n",
       " b'otherwise',\n",
       " b'exists',\n",
       " b'la',\n",
       " b'clearly',\n",
       " b'interest',\n",
       " b'completely',\n",
       " b'bought',\n",
       " b'basis',\n",
       " b't',\n",
       " b'directory',\n",
       " b'sources',\n",
       " b'freedom',\n",
       " b'ed',\n",
       " b'air',\n",
       " b'baseball',\n",
       " b'tape',\n",
       " b'currently',\n",
       " b'brian',\n",
       " b'population',\n",
       " b'dr',\n",
       " b'design',\n",
       " b'purpose',\n",
       " b'family',\n",
       " b'cover',\n",
       " b'youll',\n",
       " b'reply',\n",
       " b'issues',\n",
       " b'ii',\n",
       " b'field',\n",
       " b'average',\n",
       " b'useful',\n",
       " b'ram',\n",
       " b'division',\n",
       " b'sounds',\n",
       " b'player',\n",
       " b'inside',\n",
       " b'sale',\n",
       " b'language',\n",
       " b'batf',\n",
       " b'supposed',\n",
       " b'serious',\n",
       " b'christianity',\n",
       " b'gives',\n",
       " b'arms',\n",
       " b'looked',\n",
       " b'cut',\n",
       " b'manager',\n",
       " b'indeed',\n",
       " b'faster',\n",
       " b'below',\n",
       " b'approved',\n",
       " b'newsgroup',\n",
       " b'reasons',\n",
       " b'engine',\n",
       " b'machines',\n",
       " b'tv',\n",
       " b'follow',\n",
       " b'controller',\n",
       " b'suggest',\n",
       " b'living',\n",
       " b'morality',\n",
       " b'gave',\n",
       " b'f',\n",
       " b'choice',\n",
       " b'chance',\n",
       " b'basic',\n",
       " b'individual',\n",
       " b'eg',\n",
       " b'base',\n",
       " b'existence',\n",
       " b'project',\n",
       " b'belief',\n",
       " b'reasonable',\n",
       " b'main',\n",
       " b'create',\n",
       " b'wish',\n",
       " b'father',\n",
       " b'u',\n",
       " b'media',\n",
       " b'obviously',\n",
       " b'muslims',\n",
       " b'cards',\n",
       " b'rules',\n",
       " b'required',\n",
       " b'finally',\n",
       " b'child',\n",
       " b'built',\n",
       " b'son',\n",
       " b'development',\n",
       " b'court',\n",
       " b'normal',\n",
       " b'shot',\n",
       " b'scientific',\n",
       " b'jpeg',\n",
       " b'figure',\n",
       " b'directly',\n",
       " b'engineering',\n",
       " b'die',\n",
       " b'device',\n",
       " b'neither',\n",
       " b'mouse',\n",
       " b'meaning',\n",
       " b'fri',\n",
       " b'plan',\n",
       " b'thank',\n",
       " b'terms',\n",
       " b'necessarily',\n",
       " b'serial',\n",
       " b'k',\n",
       " b'genocide',\n",
       " b'learn',\n",
       " b'interface',\n",
       " b'lots',\n",
       " b'entire',\n",
       " b'condition',\n",
       " b'al',\n",
       " b'stated',\n",
       " b'product',\n",
       " b'mon',\n",
       " b'tom',\n",
       " b'greek',\n",
       " b'site',\n",
       " ...]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1BY6TRuoLMJs",
    "outputId": "2a88d98d-e7a6-4365-8b41-e719e7728758"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'the'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-f527d1d75381>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"the\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"cat\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"sat\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"on\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"the\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"mat\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-16-f527d1d75381>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"the\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"cat\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"sat\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"on\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"the\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"mat\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: 'the'"
     ]
    }
   ],
   "source": [
    "test = [\"the\", \"cat\", \"sat\", \"on\", \"the\", \"mat\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-U-4teStLMii"
   },
   "source": [
    "## 3. Load Pre-trained Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:/Users/user/study/HandsOnDL/sub_materials/glove\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fgLdRwoYMJ67",
    "outputId": "31e296b1-58c6-47c0-9513-b1a0b20afcd2"
   },
   "outputs": [],
   "source": [
    "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "!unzip -q glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "Xg4kHSCjMSpa",
    "outputId": "76dc6ffe-428e-4238-f511-c71a7b515689"
   },
   "outputs": [],
   "source": [
    "path_to_glove_file = os.path.join(\n",
    "    os.path.expanduser(\"~\"), \".keras/datasets/glove.6B.100d.txt\"\n",
    ")\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(path_to_glove_file) as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(\"Found %s word vectors.\" % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UMZSHSd3MS75"
   },
   "outputs": [],
   "source": [
    "num_tokens = len(voc) + 2\n",
    "embedding_dim = 100\n",
    "hits = 0\n",
    "misses = 0\n",
    "\n",
    "# Prepare embedding matrix\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        # This includes the representation for \"padding\" and \"OOV\"\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "print(\"Converted %d words (%d misses)\" % (hits, misses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OBu_OJOZMVj4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "PT2_use_pretrained_wordembedding",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
